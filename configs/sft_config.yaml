# SFT Config — Qwen-2.5-3B on 2×A100 40GB
# Chain-of-thought supervised fine-tuning

model:
  name: "Qwen/Qwen2.5-3B"
  dtype: "bf16"

training:
  micro_batch_size: 3
  gradient_accumulation_steps: 4
  # Effective batch = 2 × 4 × 2 GPUs = 16
  seq_len: 512
  num_steps: 300
  warmup_steps: 30

optimizer:
  type: "adamw"
  lr: 2.0e-5
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8

scheduler:
  type: "cosine"
  min_lr: 2.0e-6

fsdp:
  sharding_strategy: "FULL_SHARD"
  mixed_precision: "bf16"
  activation_checkpointing: true
  forward_prefetch: true

data:
  dataset: "open-r1/OpenR1-Math-220k"
  subset: "default"
  split: "train"
  max_samples: 10000  # subset for weekend project
  think_tag: "<think>"
  answer_tag: "<answer>"

logging:
  log_every: 10
  save_every: 100
  output_dir: "checkpoints/sft"

profiling:
  enabled: false  # toggle for nsys runs
  warmup_steps: 10
  capture_steps: 20
